from __future__ import annotations

"""
EmbeddingClient
---------------

å‚è€ƒ RAGFlow çš„å®ç°æ–¹å¼ï¼Œä½¿ç”¨ OpenAI SDK ä½œä¸ºåŸºç¡€å®¢æˆ·ç«¯ã€‚

ä¸ RAGFlow ä¸­çš„ embedding_model ç±»ä¼¼ï¼Œè¿™é‡Œåªå…³æ³¨ã€Œç»™å®šä¸€æ‰¹æ–‡æœ¬ â†’ è¿”å›ä¸€æ‰¹å‘é‡ã€ã€‚
"""

from dataclasses import dataclass, field
from typing import List, Optional, Any
import os
import time

from openai import OpenAI, AsyncOpenAI
from config import AppConfig, EmbeddingConfig

# --- è¡¥ä¸ï¼šç»•è¿‡ transformers çš„å¼ºåˆ¶ç‰ˆæœ¬æ£€æŸ¥ (CVE-2025-32434) ---
def patch_transformers_security_check():
    try:
        import transformers.utils.import_utils as iu
        iu.check_torch_load_is_safe = lambda: None
        import transformers.utils as u
        if hasattr(u, "check_torch_load_is_safe"):
            u.check_torch_load_is_safe = lambda: None
        import transformers.modeling_utils as mu
        if hasattr(mu, "check_torch_load_is_safe"):
            mu.check_torch_load_is_safe = lambda: None
    except Exception:
        pass

# åœ¨æœ¬åœ°æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å¯¼å…¥ FlagEmbedding å‰æ‰§è¡Œè¡¥ä¸
# å› ä¸º FlagEmbedding å†…éƒ¨ä¼šå¯¼å…¥ transformers
patch_transformers_security_check()
# ---------------------------------------------------

Vector = List[float]


@dataclass
class EmbeddingClient:
    """
    Embedding å®¢æˆ·ç«¯ï¼Œæ”¯æŒ API å’Œ æœ¬åœ° (BGE-M3) æ¨¡å¼ã€‚
    """
    
    cfg: EmbeddingConfig
    client: Optional[OpenAI] = None
    async_client: Optional[AsyncOpenAI] = None
    _local_model: Any = field(default=None, repr=False)

    @classmethod
    def from_config(cls, app_cfg: AppConfig) -> "EmbeddingClient":
        """ä»é…ç½®åˆ›å»ºå®¢æˆ·ç«¯"""
        cfg = app_cfg.embedding
        
        if cfg.mode == "local":
            print(f"     ğŸš€ æ­£åœ¨åˆå§‹åŒ–æœ¬åœ° Embedding æ¨¡å‹: {cfg.model}...")
            try:
                # 1. ä¼˜å…ˆè®¾ç½®ç¦»çº¿ç¯å¢ƒå˜é‡
                os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
                os.environ["HF_HUB_OFFLINE"] = "1"  # å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
                
                from FlagEmbedding import BGEM3FlagModel
                from huggingface_hub import snapshot_download
                
                # 2. è·å–æœ¬åœ°ç¼“å­˜çš„ç»å¯¹è·¯å¾„ï¼ˆä¸å†è”ç½‘ï¼Œç›´æ¥æŸ¥æœ¬åœ°ï¼‰
                try:
                    local_model_path = snapshot_download(
                        repo_id=cfg.model,
                        local_files_only=True, # å¼ºåˆ¶åªæŸ¥æ‰¾æœ¬åœ°
                        ignore_patterns=["imgs/*", ".DS_Store", "*.pdf", "*.png"]
                    )
                except Exception:
                    # å¦‚æœå¼ºåˆ¶ç¦»çº¿æŸ¥æ‰¾å¤±è´¥ï¼Œå°è¯•æ­£å¸¸è·¯å¾„ï¼ˆå¯èƒ½ç”±äº snapshots è½¯è¿æ¥é—®é¢˜ï¼‰
                    local_model_path = cfg.model

                # 3. åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
                model = BGEM3FlagModel(local_model_path, use_fp16=False)
                print(f"     âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸ (è·¯å¾„: {local_model_path})")
                return cls(cfg=cfg, _local_model=model)
            except ImportError:
                raise RuntimeError("æœªå®‰è£… FlagEmbedding åº“ã€‚è¯·æ‰§è¡Œ: pip install FlagEmbedding")
            except Exception as e:
                raise RuntimeError(f"æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        
        # API æ¨¡å¼
        timeout = int(os.environ.get("LLM_TIMEOUT_SECONDS", int(cfg.timeout)))
        client = OpenAI(
            api_key=cfg.api_key,
            base_url=cfg.base_url,
            timeout=timeout,
        )
        async_client = AsyncOpenAI(
            api_key=cfg.api_key,
            base_url=cfg.base_url,
            timeout=timeout,
        )
        
        return cls(cfg=cfg, client=client, async_client=async_client)

    def embed_texts(self, texts: List[str], verbose: bool = False, batch_size: int = 10) -> List[Vector]:
        """å°†ä¸€æ‰¹æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""
        if not texts:
            return []

        # 1. æœ¬åœ°æ¨¡å¼å¤„ç†
        if self.cfg.mode == "local" and self._local_model:
            if verbose:
                print(f"     â³ æ­£åœ¨ä½¿ç”¨æœ¬åœ° BGE-M3 è¿›è¡Œå‘é‡åŒ– (æ–‡æœ¬æ•°: {len(texts)})...")
            
            start_time = time.time()
            # BGE-M3 é»˜è®¤åªè¿”å› dense_vecsï¼Œé€‚åˆç°æœ‰çš„æ£€ç´¢é€»è¾‘
            output = self._local_model.encode(texts, return_dense=True)
            vectors = output['dense_vecs'].tolist()
            
            if verbose:
                print(f"     âœ… æœ¬åœ°å‘é‡åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")
            return vectors

        # 2. API æ¨¡å¼å¤„ç† (ä¿ç•™åŸæœ‰é€»è¾‘)
        if not self.client:
            raise RuntimeError("å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        if verbose:
            total_chars = sum(len(t) for t in texts)
            print(f"     å‡†å¤‡è°ƒç”¨ API: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œæ€»é•¿åº¦ {total_chars} å­—ç¬¦")
            print(f"     API: {self.cfg.base_url}")
            print(f"     æ¨¡å‹: {self.cfg.model}")
            print(f"     æ‰¹å¤„ç†å¤§å°: {batch_size}")

        try:
            start_time = time.time()
            all_vectors: List[Vector] = []
            
            # å¦‚æœæ–‡æœ¬æ•°é‡è¶…è¿‡ batch_sizeï¼Œéœ€è¦åˆ†æ‰¹å¤„ç†
            if len(texts) > batch_size:
                for i in range(0, len(texts), batch_size):
                    batch_texts = texts[i:i + batch_size]
                    if i > 0:
                        time.sleep(2.0)  # è§„é¿ API é¢‘ç‡é™åˆ¶
                    
                    response = self.client.embeddings.create(
                        model=self.cfg.model,
                        input=batch_texts,
                    )
                    all_vectors.extend([item.embedding for item in response.data])
            else:
                response = self.client.embeddings.create(
                    model=self.cfg.model,
                    input=texts,
                )
                all_vectors = [item.embedding for item in response.data]
            
            return all_vectors
            
        except Exception as e:
            raise RuntimeError(f"Embedding è°ƒç”¨å¤±è´¥: {str(e)}") from e

    async def async_embed_texts(self, texts: List[str]) -> List[Vector]:
        """å¼‚æ­¥å‘é‡åŒ–"""
        if not texts:
            return []

        try:
            response = await self.async_client.embeddings.create(
                model=self.cfg.model,
                input=texts,
            )
            
            vectors: List[Vector] = [item.embedding for item in response.data]
            
            if len(vectors) != len(texts):
                raise RuntimeError(
                    f"Embedding æ•°é‡ä¸è¾“å…¥ä¸ä¸€è‡´: {len(vectors)} vs {len(texts)}"
                )
            
            return vectors
            
        except Exception as e:
            raise RuntimeError(f"Embedding å¼‚æ­¥è°ƒç”¨å¤±è´¥: {str(e)}") from e


__all__ = ["EmbeddingClient", "Vector"]

