#!/usr/bin/env python3
"""
RAG å¼•æ“ä¸»å…¥å£
-------------

ä¸»è¦åŠŸèƒ½ï¼šä»é…ç½®æ–‡ä»¶åŠ è½½çŸ¥è¯†åº“

æ”¯æŒä¸¤ç§é…ç½®æ–¹å¼ï¼š
1. ä½¿ç”¨ JSON é…ç½®æ–‡ä»¶ï¼ˆknowledge_bases.jsonï¼‰
2. ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆ.env æ–‡ä»¶ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰çŸ¥è¯†åº“ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰
    python main.py

    # ä»é…ç½®æ–‡ä»¶åŠ è½½æŒ‡å®šçš„çŸ¥è¯†åº“
    python main.py --kb-id recipes_kb

    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
    python main.py --config custom_config.json

    # å…¶ä»–è¾…åŠ©åŠŸèƒ½
    python main.py query --kb-id my_kb --question "ä½ çš„é—®é¢˜"
    python main.py stats --kb-id my_kb
"""

import sys
import argparse
import json
from pathlib import Path
from typing import List, Optional

from rag import RAGEngine
from config import AppConfig, KnowledgeBaseConfig


def ingest_document(kb_id: str, file_path: str, **kwargs):
    """
    åŠ è½½å•ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼ˆè§¦å‘è§£æã€åˆ‡å—ã€å‘é‡åŒ–ã€å­˜å‚¨ï¼‰ã€‚
    
    Args:
        kb_id: çŸ¥è¯†åº“ ID
        file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
        **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚ use_markdown_header_splitï¼‰
    """
    print(f"æ­£åœ¨åŠ è½½æ–‡æ¡£: {file_path}")
    print(f"çŸ¥è¯†åº“ ID: {kb_id}")
    print("-" * 60)
    
    # åˆå§‹åŒ– RAG å¼•æ“
    engine = RAGEngine(
        kb_id=kb_id,
        use_markdown_header_split=kwargs.get("use_markdown_header_split", True),
    )
    
    # è§¦å‘åŠ è½½å’Œåˆ‡å—ï¼ˆè¿™é‡Œä¼šè°ƒç”¨ ingest_documentï¼Œå†…éƒ¨ä¼šè§¦å‘è§£æã€åˆ‡å—ã€å‘é‡åŒ–ã€å­˜å‚¨ï¼‰
    try:
        result = engine.ingest_document(file_path)
        
        print("âœ… æ–‡æ¡£åŠ è½½æˆåŠŸï¼")
        print(f"   æ–‡æ¡£ ID: {result['doc_id']}")
        print(f"   åˆ†å—æ•°é‡: {result['chunks_count']}")
        print(f"   çŠ¶æ€: {result['status']}")
        
        return True
    except Exception as e:
        print(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def ingest_directory(kb_id: str, dir_path: str, pattern: str = "**/*", **kwargs):
    """
    æ‰¹é‡åŠ è½½ç›®å½•ä¸­çš„æ–‡æ¡£ã€‚
    
    Args:
        kb_id: çŸ¥è¯†åº“ ID
        dir_path: ç›®å½•è·¯å¾„
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰æ–‡ä»¶ï¼‰
        **kwargs: å…¶ä»–å‚æ•°
    """
    dir_path = Path(dir_path)
    if not dir_path.exists() or not dir_path.is_dir():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
        return False
    
    print(f"æ­£åœ¨æ‰¹é‡åŠ è½½æ–‡æ¡£: {dir_path}")
    print(f"çŸ¥è¯†åº“ ID: {kb_id}")
    print(f"åŒ¹é…æ¨¡å¼: {pattern}")
    print("-" * 60)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
    files = list(dir_path.glob(pattern))
    
    # è¿‡æ»¤å‡ºæ”¯æŒçš„æ–‡ä»¶ç±»å‹
    supported_extensions = {".txt", ".md", ".markdown", ".mdx"}
    files = [f for f in files if f.suffix.lower() in supported_extensions]
    
    if not files:
        print(f"âŒ æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶ï¼ˆæ”¯æŒ: {supported_extensions}ï¼‰")
        return False
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡æ¡£æ–‡ä»¶")
    print("-" * 60)
    
    # åˆå§‹åŒ– RAG å¼•æ“ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡ï¼‰
    engine = RAGEngine(
        kb_id=kb_id,
        use_markdown_header_split=kwargs.get("use_markdown_header_split", True),
    )
    
    # é€ä¸ªåŠ è½½æ–‡æ¡£
    success_count = 0
    fail_count = 0
    
    import time
    total_start = time.time()
    
    for i, file_path in enumerate(files, 1):
        print(f"\n{'='*60}")
        print(f"[{i}/{len(files)}] å¤„ç†æ–‡æ¡£: {file_path.name}")
        print(f"{'='*60}")
        
        file_start = time.time()
        try:
            result = engine.ingest_document(file_path, verbose=True)
            file_time = time.time() - file_start
            print(f"\nâœ… æ–‡æ¡£å¤„ç†æˆåŠŸ - åˆ†å—æ•°: {result['chunks_count']}, æ€»è€—æ—¶: {file_time:.2f} ç§’")
            success_count += 1
        except Exception as e:
            file_time = time.time() - file_start
            print(f"\nâŒ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼Œè€—æ—¶: {file_time:.2f} ç§’")
            print(f"   é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            fail_count += 1
    
    print("\n" + "=" * 60)
    print("æ‰¹é‡åŠ è½½å®Œæˆ")
    print(f"  æˆåŠŸ: {success_count}")
    print(f"  å¤±è´¥: {fail_count}")
    print(f"  æ€»è®¡: {len(files)}")
    
    return fail_count == 0


def query_knowledge_base(kb_id: str, question: str, top_k: int = 4):
    """
    æŸ¥è¯¢çŸ¥è¯†åº“ã€‚
    
    Args:
        kb_id: çŸ¥è¯†åº“ ID
        question: é—®é¢˜
        top_k: æ£€ç´¢çš„æ–‡æ¡£å—æ•°é‡
    """
    print(f"é—®é¢˜: {question}")
    print(f"çŸ¥è¯†åº“ ID: {kb_id}")
    print("-" * 60)
    
    # åˆå§‹åŒ– RAG å¼•æ“
    engine = RAGEngine(kb_id=kb_id)
    
    try:
        # æŸ¥è¯¢
        result = engine.query(question, top_k=top_k)
        
        print("\nğŸ“š æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å—:")
        for i, chunk in enumerate(result.get("chunks", []), 1):
            print(f"\n  [{i}] ç›¸ä¼¼åº¦: {chunk.get('score', 0):.4f}")
            print(f"      å†…å®¹: {chunk.get('text', '')[:100]}...")
            if chunk.get("metadata"):
                print(f"      å…ƒæ•°æ®: {chunk['metadata']}")
        
        print("\nğŸ¤– AI å›ç­”:")
        print(f"  {result.get('answer', '')}")
        
        return True
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def show_stats(kb_id: str):
    """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
    print(f"çŸ¥è¯†åº“ ID: {kb_id}")
    print("-" * 60)
    
    # åˆå§‹åŒ– RAG å¼•æ“
    engine = RAGEngine(kb_id=kb_id)
    
    try:
        stats = engine.get_stats()
        
        print("ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å‘é‡æ•°é‡: {stats.get('vector_count', 0)}")
        print(f"   æ–‡æ¡£æ•°é‡: {stats.get('document_count', 0)}")
        
        if stats.get("categories"):
            print(f"   åˆ†ç±»åˆ†å¸ƒ: {stats['categories']}")
        
        if stats.get("difficulties"):
            print(f"   éš¾åº¦åˆ†å¸ƒ: {stats['difficulties']}")
        
        return True
    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def load_config_from_json(config_path: str) -> List[KnowledgeBaseConfig]:
    """
    ä» JSON é…ç½®æ–‡ä»¶åŠ è½½çŸ¥è¯†åº“é…ç½®ã€‚
    
    Args:
        config_path: JSON é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        çŸ¥è¯†åº“é…ç½®åˆ—è¡¨
    """
    config_path = Path(config_path)
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    
    kb_configs = []
    for kb in config.get("knowledge_bases", []):
        kb_configs.append(KnowledgeBaseConfig(
            kb_id=kb["kb_id"],
            source_path=kb["source_path"],
            file_pattern=kb.get("file_pattern", "*.md"),
            use_markdown_header_split=kb.get("use_markdown_header_split", True),
        ))
    
    return kb_configs


def find_markdown_files(directory: Path, pattern: str = "*.md") -> List[Path]:
    """
    é€’å½’æŸ¥æ‰¾ç›®å½•ä¸­åŒ¹é…æ¨¡å¼çš„æ–‡ä»¶ã€‚
    
    Args:
        directory: ç›®å½•è·¯å¾„
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤ï¼š*.mdï¼‰
    
    Returns:
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    files = []
    for file_path in directory.rglob(pattern):
        if file_path.is_file():
            files.append(file_path)
    return sorted(files)


def load_knowledge_base(kb_config: KnowledgeBaseConfig, verbose: bool = True):
    """
    åŠ è½½å•ä¸ªçŸ¥è¯†åº“ã€‚
    
    Args:
        kb_config: çŸ¥è¯†åº“é…ç½®
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    source_path = Path(kb_config.source_path)
    
    if not source_path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {source_path}")
        return False
    
    if not source_path.is_dir():
        print(f"âŒ ä¸æ˜¯ç›®å½•: {source_path}")
        return False
    
    if verbose:
        print("=" * 60)
        print(f"åŠ è½½çŸ¥è¯†åº“: {kb_config.kb_id}")
        print("=" * 60)
        print(f"æºè·¯å¾„: {source_path}")
        print(f"æ–‡ä»¶æ¨¡å¼: {kb_config.file_pattern}")
        print("-" * 60)
    
    # æŸ¥æ‰¾æ–‡ä»¶
    if verbose:
        print("æ­£åœ¨æ‰«ææ–‡ä»¶...")
    files = find_markdown_files(source_path, kb_config.file_pattern)
    
    if not files:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼ˆæ¨¡å¼: {kb_config.file_pattern}ï¼‰")
        return False
    
    if verbose:
        print(f"âœ… æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
        print("-" * 60)
    
    # åˆå§‹åŒ– RAG å¼•æ“
    if verbose:
        print("åˆå§‹åŒ– RAG å¼•æ“...")
    engine = RAGEngine(
        kb_id=kb_config.kb_id,
        use_markdown_header_split=kb_config.use_markdown_header_split,
    )
    if verbose:
        print("âœ… RAG å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print("-" * 60)
    
    # æ‰¹é‡åŠ è½½æ–‡æ¡£
    if verbose:
        print(f"\nå¼€å§‹åŠ è½½æ–‡æ¡£...\n")
    success_count = 0
    fail_count = 0
    
    for i, file_path in enumerate(files, 1):
        try:
            rel_path = file_path.relative_to(source_path)
        except ValueError:
            rel_path = file_path.name
        
        if verbose:
            print(f"[{i}/{len(files)}] {rel_path}", end=" ... ")
        
        try:
            result = engine.ingest_document(file_path)
            if verbose:
                print(f"âœ… æˆåŠŸ ({result['chunks_count']} å—)")
            success_count += 1
        except Exception as e:
            if verbose:
                print(f"âŒ å¤±è´¥: {e}")
            fail_count += 1
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if verbose:
        print("\n" + "=" * 60)
        print("åŠ è½½å®Œæˆ")
        print("=" * 60)
        print(f"  æˆåŠŸ: {success_count}")
        print(f"  å¤±è´¥: {fail_count}")
        print(f"  æ€»è®¡: {len(files)}")
        
        if success_count > 0:
            print("\nçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
            try:
                stats = engine.get_stats()
                print(f"  å‘é‡æ•°é‡: {stats.get('vector_count', 0)}")
                print(f"  æ–‡æ¡£æ•°é‡: {stats.get('document_count', 0)}")
            except Exception as e:
                print(f"  è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    return fail_count == 0


def load_all_knowledge_bases(config_path: str = "knowledge_bases.json", kb_id: Optional[str] = None, quiet: bool = False):
    """
    ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰çŸ¥è¯†åº“ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰ã€‚
    
    Args:
        config_path: JSON é…ç½®æ–‡ä»¶è·¯å¾„
        kb_id: åªåŠ è½½æŒ‡å®šçš„çŸ¥è¯†åº“ IDï¼ˆå¦‚æœä¸æŒ‡å®šï¼ŒåŠ è½½æ‰€æœ‰ï¼‰
        quiet: é™é»˜æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰
    """
    # åŠ è½½çŸ¥è¯†åº“é…ç½®
    kb_configs = []
    
    # æ–¹å¼ä¸€ï¼šä» JSON é…ç½®æ–‡ä»¶åŠ è½½
    config_file = Path(config_path)
    if config_file.exists():
        try:
            kb_configs = load_config_from_json(config_path)
            if not quiet:
                print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½: {config_path}")
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    else:
        # æ–¹å¼äºŒï¼šä»ç¯å¢ƒå˜é‡åŠ è½½
        try:
            app_config = AppConfig.load()
            if app_config.knowledge_bases:
                kb_configs = app_config.knowledge_bases
                if not quiet:
                    print("âœ… ä»ç¯å¢ƒå˜é‡åŠ è½½çŸ¥è¯†åº“é…ç½®")
            else:
                print("âŒ æœªæ‰¾åˆ°çŸ¥è¯†åº“é…ç½®ï¼ˆè¯·æ£€æŸ¥ knowledge_bases.json æˆ–ç¯å¢ƒå˜é‡ï¼‰")
                return False
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            return False
    
    if not kb_configs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“é…ç½®")
        return False
    
    # è¿‡æ»¤æŒ‡å®šçš„çŸ¥è¯†åº“
    if kb_id:
        kb_configs = [kb for kb in kb_configs if kb.kb_id == kb_id]
        if not kb_configs:
            print(f"âŒ æœªæ‰¾åˆ°çŸ¥è¯†åº“: {kb_id}")
            return False
    
    # åŠ è½½çŸ¥è¯†åº“
    all_success = True
    for kb_config in kb_configs:
        success = load_knowledge_base(kb_config, verbose=not quiet)
        if not success:
            all_success = False
        if not quiet and len(kb_configs) > 1:
            print()  # ç©ºè¡Œåˆ†éš”
    
    if all_success:
        if not quiet:
            print("âœ… æ‰€æœ‰çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼")
        return True
    else:
        if not quiet:
            print("âš ï¸  éƒ¨åˆ†çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="RAG å¼•æ“ä¸»å…¥å£ï¼ˆä¸»è¦åŠŸèƒ½ï¼šåŠ è½½çŸ¥è¯†åº“ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    
    # ä¸»åŠŸèƒ½ï¼šåŠ è½½çŸ¥è¯†åº“ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
    parser.add_argument(
        "--config",
        default="knowledge_bases.json",
        help="JSON é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: knowledge_bases.jsonï¼‰",
    )
    parser.add_argument(
        "--kb-id",
        help="åªåŠ è½½æŒ‡å®šçš„çŸ¥è¯†åº“ IDï¼ˆå¦‚æœä¸æŒ‡å®šï¼ŒåŠ è½½æ‰€æœ‰ï¼‰",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰",
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å…¶ä»–å‘½ä»¤ï¼ˆå¯é€‰ï¼‰")
    
    # ingest å‘½ä»¤ï¼šåŠ è½½æ–‡æ¡£
    ingest_parser = subparsers.add_parser("ingest", help="åŠ è½½æ–‡æ¡£åˆ°çŸ¥è¯†åº“")
    ingest_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    ingest_parser.add_argument("--file", help="å•ä¸ªæ–‡æ¡£æ–‡ä»¶è·¯å¾„")
    ingest_parser.add_argument("--dir", help="æ–‡æ¡£ç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡åŠ è½½ï¼‰")
    ingest_parser.add_argument("--pattern", default="**/*", help="æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆæ‰¹é‡åŠ è½½æ—¶ä½¿ç”¨ï¼‰")
    ingest_parser.add_argument("--no-markdown-split", action="store_true", help="ç¦ç”¨ Markdown æ ‡é¢˜åˆ†å‰²")
    
    # query å‘½ä»¤ï¼šæŸ¥è¯¢çŸ¥è¯†åº“
    query_parser = subparsers.add_parser("query", help="æŸ¥è¯¢çŸ¥è¯†åº“")
    query_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    query_parser.add_argument("--question", required=True, help="é—®é¢˜")
    query_parser.add_argument("--top-k", type=int, default=4, help="æ£€ç´¢çš„æ–‡æ¡£å—æ•°é‡")
    
    # stats å‘½ä»¤ï¼šæŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    stats_parser = subparsers.add_parser("stats", help="æŸ¥çœ‹çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
    stats_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‘½ä»¤ï¼Œé»˜è®¤æ‰§è¡ŒåŠ è½½çŸ¥è¯†åº“ï¼ˆä¸»è¦åŠŸèƒ½ï¼‰
    if not args.command:
        return 0 if load_all_knowledge_bases(
            config_path=args.config,
            kb_id=args.kb_id,
            quiet=args.quiet,
        ) else 1
    
    # æ‰§è¡Œå…¶ä»–å‘½ä»¤
    if args.command == "ingest":
        if args.file:
            # åŠ è½½å•ä¸ªæ–‡æ¡£
            success = ingest_document(
                args.kb_id,
                args.file,
                use_markdown_header_split=not args.no_markdown_split,
            )
        elif args.dir:
            # æ‰¹é‡åŠ è½½
            success = ingest_directory(
                args.kb_id,
                args.dir,
                pattern=args.pattern,
                use_markdown_header_split=not args.no_markdown_split,
            )
        else:
            print("âŒ è¯·æŒ‡å®š --file æˆ– --dir å‚æ•°")
            return 1
        
        return 0 if success else 1
    
    elif args.command == "query":
        success = query_knowledge_base(
            args.kb_id,
            args.question,
            top_k=args.top_k,
        )
        return 0 if success else 1
    
    elif args.command == "stats":
        success = show_stats(args.kb_id)
        return 0 if success else 1
    
    else:
        parser.print_help()
        return 1


if __name__ == "__main__":
    sys.exit(main())

