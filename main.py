#!/usr/bin/env python3
"""
RAG å¼•æ“ä¸»å…¥å£
-------------

ç»Ÿä¸€ç®¡ç†çŸ¥è¯†åº“çš„åŠ è½½ã€æŸ¥è¯¢å’Œç»Ÿè®¡ã€‚
"""

import sys
import argparse
import json
from pathlib import Path
from typing import List, Optional

from rag import RAGEngine
from config import AppConfig, KnowledgeBaseConfig


def load_config_from_json(config_path: str) -> List[KnowledgeBaseConfig]:
    """ä» JSON é…ç½®æ–‡ä»¶åŠ è½½çŸ¥è¯†åº“é…ç½®"""
    config_path = Path(config_path)
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    
    kb_configs = []
    for kb in config.get("knowledge_bases", []):
        kb_configs.append(KnowledgeBaseConfig(
            kb_id=kb["kb_id"],
            source_path=kb["source_path"],
            file_pattern=kb.get("file_pattern", "*.md"),
            use_markdown_header_split=kb.get("use_markdown_header_split", True),
        ))
    
    return kb_configs


def handle_ingest(args):
    """å¤„ç†åŠ è½½æ–‡æ¡£çš„é€»è¾‘"""
    engine = RAGEngine(
        kb_id=args.kb_id,
        use_markdown_header_split=not args.no_markdown_split,
    )
    
    if args.file:
        print(f"æ­£åœ¨åŠ è½½å•ä¸ªæ–‡æ¡£: {args.file}")
        result = engine.ingest_document(args.file)
        print(f"âœ… æˆåŠŸ - åˆ†å—æ•°: {result['chunks_count']}")
    elif args.dir:
        result = engine.ingest_directory(
            dir_path=args.dir,
            pattern=args.pattern,
            verbose=True
        )
        print("\n" + "=" * 40)
        print("æ‰¹é‡åŠ è½½å®Œæˆ")
        print(f"  æˆåŠŸ: {result['success_count']}")
        print(f"  å¤±è´¥: {result['fail_count']}")
        print(f"  æ€»è®¡: {result['total_files']}")
        print(f"  æ€»åˆ†å—æ•°: {result['total_chunks']}")
    else:
        print("âŒ è¯·æŒ‡å®š --file æˆ– --dir å‚æ•°")
        return 1
    return 0


def handle_load_all(args):
    """æ ¹æ®é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰çŸ¥è¯†åº“"""
    kb_configs = []
    config_file = Path(args.config)
    
    if config_file.exists():
        kb_configs = load_config_from_json(args.config)
        print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½: {args.config}")
    else:
        app_config = AppConfig.load()
        if app_config.knowledge_bases:
            kb_configs = app_config.knowledge_bases
            print("âœ… ä»ç¯å¢ƒå˜é‡åŠ è½½çŸ¥è¯†åº“é…ç½®")
    
    if not kb_configs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“é…ç½®")
        return 1
    
    if args.kb_id:
        kb_configs = [kb for kb in kb_configs if kb.kb_id == args.kb_id]
    
    for kb_config in kb_configs:
        print(f"\nå¼€å§‹åŠ è½½çŸ¥è¯†åº“: {kb_config.kb_id}")
        engine = RAGEngine(
            kb_id=kb_config.kb_id,
            use_markdown_header_split=kb_config.use_markdown_header_split,
        )
        engine.ingest_directory(
            dir_path=kb_config.source_path,
            pattern=kb_config.file_pattern,
            verbose=True
        )
    return 0


def handle_query(args):
    """å¤„ç†æŸ¥è¯¢é€»è¾‘"""
    engine = RAGEngine(kb_id=args.kb_id)
    result = engine.query(args.question, top_k=args.top_k)
    
    print("\nğŸ“š æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹:")
    for i, chunk in enumerate(result.get("chunks", []), 1):
        print(f"  [{i}] (Score: {chunk.get('score', 0):.4f}) {chunk.get('text', '')[:100]}...")
    
    print("\nğŸ¤– AI å›ç­”:")
    print(f"  {result.get('answer', '')}")
    return 0


def handle_stats(args):
    """å¤„ç†ç»Ÿè®¡é€»è¾‘"""
    engine = RAGEngine(kb_id=args.kb_id)
    stats = engine.get_stats()
    print(f"\nğŸ“Š çŸ¥è¯†åº“ [{args.kb_id}] ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å‘é‡æ•°é‡: {stats.get('vector_count', 0)}")
    print(f"   å‘é‡ç»´åº¦: {stats.get('vector_dim', 'æœªçŸ¥')}")
    return 0


def main():
    parser = argparse.ArgumentParser(description="RAG å¼•æ“ç»Ÿä¸€å…¥å£")
    subparsers = parser.add_subparsers(dest="command")
    
    # 1. ingest å‘½ä»¤ (åªåšå‘é‡åŒ–å¹¶é€€å‡º)
    ingest_parser = subparsers.add_parser("ingest", help="æ‰§è¡Œå‘é‡åŒ–å¹¶ä¿å­˜åˆ°æ•°æ®åº“")
    ingest_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    ingest_parser.add_argument("--file", help="å•ä¸ªæ–‡ä»¶è·¯å¾„")
    ingest_parser.add_argument("--dir", help="æ–‡ä»¶å¤¹è·¯å¾„")
    ingest_parser.add_argument("--pattern", default="*.md", help="æ–‡ä»¶åŒ¹é…æ¨¡å¼")
    ingest_parser.add_argument("--no-markdown-split", action="store_true", help="ç¦ç”¨ Markdown æ ‡é¢˜åˆ†å‰²")
    
    # 2. query å‘½ä»¤
    query_parser = subparsers.add_parser("query", help="æŸ¥è¯¢çŸ¥è¯†åº“")
    query_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    query_parser.add_argument("--question", required=True, help="é—®é¢˜å†…å®¹")
    query_parser.add_argument("--top-k", type=int, default=4, help="æ£€ç´¢æ•°é‡")
    
    # 3. stats å‘½ä»¤
    stats_parser = subparsers.add_parser("stats", help="æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
    stats_parser.add_argument("--kb-id", required=True, help="çŸ¥è¯†åº“ ID")
    
    # é»˜è®¤è¡Œä¸ºï¼šä»é…ç½®åŠ è½½æ‰€æœ‰çŸ¥è¯†åº“
    parser.add_argument("--config", default="knowledge_bases.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--kb-id", help="æŒ‡å®šè¦åŠ è½½çš„çŸ¥è¯†åº“ ID")
    
    args = parser.parse_args()
    
    if args.command == "ingest":
        sys.exit(handle_ingest(args))
    elif args.command == "query":
        sys.exit(handle_query(args))
    elif args.command == "stats":
        sys.exit(handle_stats(args))
    else:
        # å¦‚æœæ²¡æœ‰å­å‘½ä»¤ï¼Œé»˜è®¤æ‰§è¡Œæ‰¹é‡åŠ è½½
        sys.exit(handle_load_all(args))


if __name__ == "__main__":
    main()
